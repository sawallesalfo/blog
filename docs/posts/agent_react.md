---
date: 2024-09-21
authors:
    - ssawadogo
categories: 
    - IAGen
---


# Build an Agent (2/3): From Router to React Agent

## Introduction

Dans le [premier article de cette sÃ©rie](https://sawallesalfo.github.io/blog/2025/07/14/agent-router/), nous avons construit un **Router Agent** avec une logique if/else rigide. Aujourd'hui, nous passons au **React Agent** : un agent autonome qui dÃ©cide lui-mÃªme de ses actions.

<!-- more -->

Nous verrons les concepts clÃ©s, comparerons les frameworks, et implÃ©menterons notre solution.

## Rappel : Notre Workflow PrÃ©cÃ©dent

Router Agent = chemin prÃ©dÃ©fini. React Agent = agent qui dÃ©cide lui-mÃªme Ã  chaque Ã©tape.

```python
class RouterAgent:
    
    def __init__(self, llm_client):
        self.llm = llm_client
    
    def run(self, query: str) -> Union[str, ActionOutput]:
        logger.info(f"RouterAgent processing query: {query}")
        
        sql_generator = SQLGeneratorAction(self.llm)
        result = sql_generator.execute(query=query)

        if result.grade <= 1:
            logger.info("Returning general response")
            return result.output_value

        sql_executor = SQLExecutor(mode="polars")
        sql_executor.add_table("pib_data", "C:/Users/sawal/Downloads/pib_data0.csv")
        sql_data = sql_executor.execute(result.output_value)

        if sql_data.grade < 1:
            logger.error(f"SQL execution failed: {sql_data.output_value}")
            return f"SQL execution failed: {sql_data.output_value}"

        plotter = PlotAction(self.llm)
        plot_result = plotter.execute(
            query=query,
            dataset=sql_data.output_value,
            output_format="altair"
        )

        if plot_result.grade < 1:
            logger.error(f"Chart generation failed: {plot_result.output_value}")
            return f"Chart generation failed: {plot_result.output_value}"

        logger.info("RouterAgent completed successfully")
        return plot_result.output_value

```
Router = chemin fixe. React = agent autonome qui s'adapte.

Les orchestrateurs complexes deviennent vite ingÃ©rables car ils nÃ©cessitent de maintenir des prompts avec exemples de plus en plus lourds.

## Core Concepts : Les Agents React

### DÃ©finition

Le pattern **React** = Reason-Act-Observe. L'agent raisonne â†’ agit â†’ observe â†’ rÃ©pÃ¨te.

1. **Raisonne** (Reason) : Analyse la situation et dÃ©termine la prochaine action Ã  entreprendre
2. **Agit** (Act) : ExÃ©cute l'action choisie en utilisant les outils disponibles  
3. **Observe** : Analyse le rÃ©sultat de l'action pour dÃ©cider de la suite

Ce cycle se rÃ©pÃ¨te jusqu'Ã  ce que l'agent estime avoir accompli la tÃ¢che demandÃ©e.

### Comparaison avec l'Approche Router

| **Aspect** | **Router Agent** | **React Agent** |
|------------|------------------|-----------------|
| `Orchestration` | Logique if/else explicite | LLM dÃ©cide dynamiquement |
| `FlexibilitÃ©` | LimitÃ©e au workflow prÃ©dÃ©fini | Adaptable Ã  tous scÃ©narios |
| `PrÃ©dictibilitÃ©` | Totale | Variable selon le LLM |
| `DÃ©bogage` | Simple (flux linÃ©aire) | Plus complexe (flux dynamique) |
| `Performance` | OptimisÃ©e (pas de rÃ©flexion) | DÃ©pend du LLM |
| `Ã‰volutivitÃ©` | Modification du code nÃ©cessaire | Ajout de tools suffit |

Nous approfondirons ces distinctions dans l'article prÃ©cÃ©dent qui traite de cette comparaison.

## Framework Landscape

Trop de frameworks sont disponibles sur le marchÃ©. Pour la production, nous recommandons : `Pydantic AI` et `LangGraph`. Les autres (Swarm, SmolAgent) sont plus adaptÃ©s Ã  l'apprentissage et au prototypage.


### Tableau Comparatif des Frameworks

| **Framework** | **Atouts** | **InconvÃ©nients** | **Use Case IdÃ©al** |
|---------------|------------|-------------------|---------------------|
| **LangChain** | Ã‰cosystÃ¨me riche, nombreux connecteurs | ComplexitÃ© Ã©levÃ©e, abstractions opaques | Prototypage rapide, intÃ©grations multiples |
| **LangGraph** | ContrÃ´le fin du workflow, Human in the loop, graph-based, state management | Courbe d'apprentissage Ã©levÃ©e | Workflows complexes, debugging avancÃ© |
| **SmolAgent** | SimplicitÃ©, transparence, performance | Ã‰cosystÃ¨me plus limitÃ© | Production, contrÃ´le prÃ©cis |
| **CrewAI** | Multi-agents, orchestration avancÃ©e | Overhead pour cas simples | Ã‰quipes d'agents, tÃ¢ches complexes |
| **Pydantic AI** | Type safety, AG-UI, intÃ©gration MCP, async, interruption et communautÃ© active | Ã‰cosystÃ¨me rÃ©cent, documentation en cours | Applications type-safe et prÃªtes pour la production |

Les frameworks gÃ¨rent efficacement les machines d'Ã©tat et l'orchestration de prompts, mais chacun a ses spÃ©cificitÃ©s.

### Recommandations

- **DÃ©butant** : SmolAgent 
- **Prototype** : LangChain 
- **Production** : Pydantic AI 
- **Workflows complexes** : LangGraph 
- **Multi-agents** : CrewAI

## Les Tools : Foundation des Agents React

### Pourquoi les LLM ont besoin d'outils

Les LLM prÃ©disent des tokens, ils ne calculent pas. D'oÃ¹ les erreurs frÃ©quentes sur des questions simples comme "combien de 'r' dans strawberry".

Les grands modÃ¨les de langage comme GPT-4 ou Mistral sont extraordinaires pour comprendre et gÃ©nÃ©rer du texte, mais ils ont une limitation fondamentale : **leur tÃ¢che principale est de prÃ©dire le prochain token dans une sÃ©quence**, pas d'exÃ©cuter des calculs prÃ©cis ou d'accÃ©der Ã  des informations en temps rÃ©el.

Cette limitation devient Ã©vidente avec des questions simples comme "Combien de 'r' dans le mot 'strawberry' ?" oÃ¹ mÃªme les meilleurs LLM peuvent se tromper. Ils "devinent" la rÃ©ponse basÃ©e sur leurs donnÃ©es d'entraÃ®nement plutÃ´t que de compter rÃ©ellement les lettres.

C'est pourquoi ChatGPT et Claude intÃ¨grent maintenant des outils comme des calculatrices et des interprÃ©teurs de code - pour dÃ©passer leurs propres limites et fournir des rÃ©ponses fiables.

### Concept Fondamental

Les outils Ã©tendent les capacitÃ©s des agents : calculs, bases de donnÃ©es, web, etc.

Prenons un exemple concret qui dÃ©montre cette diffÃ©rence (exemple trÃ¨s connu) :

```python
# Sans outil - Le LLM hallucine souvent
question = "Combien de 'r' y a-t-il dans le mot 'strawberry' ?"
agent.run(question)
# RÃ©ponse LLM typique : "Il y a 2 'r' dans strawberry" âŒ (Incorrect, il y en a 3)

# Avec outil - RÃ©sultat prÃ©cis
@tool
def count_letters(word: str, letter: str) -> str:
    """Compte le nombre d'occurrences d'une lettre dans un mot."""
    count = word.lower().count(letter.lower())
    return f"Le mot '{word}' contient {count} occurrence(s) de la lettre '{letter}'."
agent.add_tools(count_letters)
agent.run(question)

# RÃ©sultat : "Le mot 'strawberry' contient 3 occurrence(s) de la lettre 'r'." âœ…
```

Les outils transforment un LLM qui "devine" en agent qui "sait". Ils permettent d'avoir des rÃ©ponses factuelles plutÃ´t que des approximations.

ChatGPT et Claude utilisent des outils : calculatrice, code Python, recherche web, analyse d'images, accÃ¨s API mÃ©tÃ©o, calendrier.

D'ailleurs, rappelez-vous qu'au dÃ©but de ChatGPT, si vous demandiez la date actuelle, c'Ã©tait une date comme 2021 qui Ã©tait retournÃ©e. Aujourd'hui, le LLM appelle ses outils calendar quand il s'agit de la date actuelle.

### Ce qu'il faut pour avoir un outil

3 Ã©lÃ©ments clÃ©s pour un bon outil : docstring dÃ©taillÃ©e, types annotÃ©s, retour consistant.
```python
@tool
def example_tool(param1: str, param2: int) -> str:
    """Description claire de ce que fait l'outil.
    
    Args:
        param1: Description du premier paramÃ¨tre
        param2: Description du second paramÃ¨tre
    
    Returns:
        Description du rÃ©sultat attendu
    """
    # ImplÃ©mentation de la logique
    result = perform_action(param1, param2)
    return f"RÃ©sultat formatÃ© : {result}"
```

### DÃ©monstration Pratique

Faisons une dÃ©monstration pratique avec le framework SmolAgent.
Ã€ la fin, vous verrez que SmolAgent sans outils = erreurs de calcul. Avec outils = prÃ©cision.

SmolAgent propose : `CodeAgent` (Ã©crire du code Python et l'exÃ©cuter) vs `ToolCallingAgent` (appels JSON). Nous prÃ©fÃ©rons les appels JSON.

**Explication technique :**
- CodeAgent gÃ©nÃ¨re ses appels d'outils sous forme de snippets de code Python.
- ToolCallingAgent Ã©crit ses appels d'outils en JSON, comme c'est courant dans de nombreux frameworks.

Selon vos besoins, l'une ou l'autre approche peut Ãªtre utilisÃ©e. Par exemple, la navigation web nÃ©cessite souvent d'attendre aprÃ¨s chaque interaction de page, donc les appels d'outils JSON peuvent bien convenir. D'aprÃ¨s mes discussions avec d'autres dÃ©veloppeurs IA et data scientists, personne n'utilise CodeAgent dans un projet sÃ©rieux, surtout que la gÃ©nÃ©ration de code peut partir dans tous les sens.



#### Ã‰tape 1 : Agent sans Outils

```python
model = LiteLLMModel(
    model_id="mistral/mistral-tiny",
    api_key=os.environ.get("MISTRAL_API_KEY")
)

agent = ToolCallingAgent(
    tools=[],  # Aucun outil disponible
    model=model
)

result = agent.run("Quelle est la racine carrÃ©e de 6.12?")
```

![alt text](agent_2/smolagent_example1.png)

Comme vous pouvez le voir, le LLM a donnÃ© une mauvaise rÃ©ponse - ce qui Ã©tait attendu. Le LLM utilisÃ© est mistral-tiny (modÃ¨le trop petit), mais mÃªme pour les grands LLM, les calculs prÃ©cis ne sont pas toujours Ã©vidents.

#### Ã‰tape 2 : ImplÃ©mentation de notre premier outil

Maintenant, implÃ©mentons notre premier outil :

```python
from smolagents import tool

@tool
def square_root_smolagent(number: float) -> str:
    """Calcule la racine carrÃ©e d'un nombre.
    
    Args:
        number: Le nombre dont on veut calculer la racine carrÃ©e
    
    Returns:
        La racine carrÃ©e du nombre
    """
    import math
    try:
        result = math.sqrt(number)
        return f"La racine carrÃ©e de {number} est {result}."
    except ValueError as e:
        return f"Erreur: {str(e)}"
```

Cette implÃ©mentation reste simple, n'est-ce pas ?

#### Ã‰tape 3 : Ajout de l'outil

```python
from smolagents import ToolCallingAgent, LiteLLMModel

model = LiteLLMModel(
    model_id="mistral/mistral-tiny",
    api_key=os.environ.get("MISTRAL_API_KEY")
)

agent = ToolCallingAgent(tools=[square_root_smolagent], model=model)

result = agent.run("Quelle est la racine carrÃ©e de 6.12?")
```

![alt text](agent_2/smolagent_example2.png)

**EURÃŠKA !** La rÃ©ponse est dÃ©sormais correcte. VoilÃ , vous savez tout sur les outils et comment les intÃ©grer Ã  un LLM.

## Design Pattern : Abstraction GÃ©nÃ©rique pour Frameworks

L'un des dÃ©fis majeurs quand on travaille avec plusieurs frameworks d'agents est la nÃ©cessitÃ© de rÃ©Ã©crire les outils pour chaque framework. Voici une solution d'abstraction que j'ai dÃ©veloppÃ©e, prÃªte Ã  l'utilisation :

En gros, il faut savoir que derriÃ¨re les dÃ©corateurs, il y a des classes qui gÃ¨rent les docstrings pour les prÃ©parer. Cette abstraction consiste Ã  partir de ces classes pour passer dynamiquement nos docstrings ou informations sans passer par des fonctions avec dÃ©corateur :
Je vous invit Ã  consulter les docs officiels de ces framework pour construire des Class elegant
### Architecture de l'Abstraction

Ajouter ces mÃ©thodes dans les prÃ©cÃ©dentes classes Action :

```python
class SQLGeneratorAction(BaseAction):
    # ... (code dÃ©jÃ  vu dans l'article prÃ©cÃ©dent) ...
    
    def _create_smolagent_tool(self, **kwargs):
        """CrÃ©e un outil smolagent pour cette action"""
        @smolagents.tool
        def sql_generator_smolagent(query: str) -> str:
            """GÃ©nÃ¨re une requÃªte SQL Ã  partir d'une question en langage naturel.
            
            Args:
                query: Question de l'utilisateur en langage naturel
            
            Returns:
                RequÃªte SQL gÃ©nÃ©rÃ©e ou rÃ©ponse textuelle selon le type de question
            """
            return self.execute(query=query).output_value
        return sql_generator_smolagent

    def _create_langchain_tool(self, **kwargs):
        """CrÃ©e un outil langchain pour cette action"""
        @langchain_core.tools.tool
        def sql_generator_tool(query: str) -> str:
            """GÃ©nÃ¨re une requÃªte SQL Ã  partir d'une question en langage naturel.
            
            Args:
                query: Question de l'utilisateur en langage naturel
            
            Returns:
                RequÃªte SQL gÃ©nÃ©rÃ©e ou rÃ©ponse textuelle selon le type de question
            """
            return self.execute(query=query).output_value
        return sql_generator_tool




```python
class SQLExecutor(BaseAction):
        # ... (code dÃ©jÃ  vu dans l'article prÃ©cÃ©dent) ...


    def _create_smolagent_tool(self, **kwargs):
        """CrÃ©e un outil smolagent pour cette action"""
        @smolagents.tool
        def sql_executor_smolagent(sql_query: str) -> str:
            """ExÃ©cute un code SQL et retourne les rÃ©sultats.
            
            Args:
                sql_query: RequÃªte SQL valide Ã  exÃ©cuter (SELECT uniquement)
            
            Returns:
                RÃ©sultats de la requÃªte au format JSON string
            """
            return self.execute(sql_query=sql_query).output_value
        return sql_executor_smolagent

    def _create_langchain_tool(self, **kwargs):
        """CrÃ©e un outil langchain pour cette action"""
        @langchain_core.tools.tool
        def sql_executor_tool(sql_query: str) -> str:
            """ExÃ©cute un code SQL et retourne les rÃ©sultats.
            
            Args:
                sql_query: RequÃªte SQL valide Ã  exÃ©cuter (SELECT uniquement)
            
            Returns:
                RÃ©sultats de la requÃªte en format list
            """
            return self.execute(sql_query=sql_query).output_value
        return sql_executor_tool

```
```python
class PlotAction(BaseAction):
    # ... (code dÃ©jÃ  vu dans l'article prÃ©cÃ©dent) ...
    
    def _create_smolagent_tool(self, **kwargs):
        """CrÃ©e un outil smolagent pour cette action"""
        @smolagents.tool
        def plotter_smolagent(query: str, data: List[Dict], output_format: str = "altair") -> str:
            """CrÃ©e un graphique Altair Ã  partir de donnÃ©es et d'une description.
            
            Args:
                query: Description du graphique souhaitÃ© en langage naturel
                data: DonnÃ©es au format List[Dict]
                output_format: Format de sortie ('altair', 'html', ou 'base64')
            
            Returns:
                Graphique gÃ©nÃ©rÃ© au format demandÃ© ou message d'erreur
            """
            return self.execute(query=query, dataset=data, output_format=output_format).output_value
        return plotter_smolagent

    def _create_langchain_tool(self, **kwargs):
        """CrÃ©e un outil langchain pour cette action"""
        @langchain_core.tools.tool
        def plotter_tool(query: str, data: List[Dict], output_format: str = "altair") -> str:
            """GÃ©nÃ¨re un graphique Ã  partir des donnÃ©es gÃ©nÃ©rÃ©es selon la demande utilisateur.
            
            Args:
                query: Description du graphique souhaitÃ© en langage naturel
                data: DonnÃ©es au format List[Dict]
                output_format: Format de sortie ('altair', 'html', ou 'base64')
            
            Returns:
                Graphique gÃ©nÃ©rÃ© au format demandÃ© ou message d'erreur
            """
            return self.execute(query=query, dataset=data, output_format=output_format).output_value
        return plotter_tool
```


ImplÃ©menter cette approche nous permet de mieux gÃ©rer les docstrings et de ne plus avoir Ã  recoder notre systÃ¨me pour chaque framework. 
# Applications des Agents React

CommenÃ§ons par crÃ©er nos instances, ce sont les mÃªmes que dans l'article prÃ©cÃ©dent :

```python
# ... (instances dÃ©jÃ  vues dans l'article prÃ©cÃ©dent) ...
sql_generator = SQLGeneratorAction(llm)
sql_executor = SQLExecutor(mode="pandas")
sql_executor.add_table("pib_data", "./pib_data0.csv")
plot_generator = PlotAction(llm)
```

Allez, c'est parti pour une dÃ©monstration de React avec 2 frameworks.

### Avec SmolAgent

```python

tool1_smolagent = sql_generator.as_smolagent_tool()
tool2_smolagent = sql_executor.as_smolagent_tool() 
tool3_smolagent = plot_generator.as_smolagent_tool()

smolagent_tools = [tool1_smolagent, tool2_smolagent, tool3_smolagent]

model = smolagents.LiteLLMModel(
    model_id="mistral/mistral-tiny",
    api_key=os.environ.get("MISTRAL_API_KEY"),
)
agent_smolagent = smolagents.ToolCallingAgent(
    tools=smolagent_tools,
    model=model,
)
agent_smolagent.run("Donne-moi le PIB du Burkina Faso depuis 2020 sous forme de graphique")
```

![Ã‰tape 1](agent_2/step_1.png)
![Ã‰tapes 2 et 3](agent_2/STEP_2%20and3.png)
![RÃ©sultat final](agent_2/FINAL.png)
![Exemple SmolAgent](agent_2/smolagent_example3.png)

Comme vous pouvez le remarquer, chaque Ã©tape correspond Ã  l'utilisation d'un outil spÃ©cifique et l'appel des outils se fait avec la ligne :

```
Calling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Calling tool: 'sql_executor_smolagent' with arguments: {'sql_query': "SELECT year, value FROM pib_data WHERE    â”‚
â”‚ country_code = 'BFA' AND year >= '2020' ORDER BY year;"}                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

Cette interactivitÃ© et ces logs font la force de SmolAgent.

### Avec LangChain/LangGraph

```python
tool1_langchain = sql_generator.as_langchain_tool()
tool2_langchain = sql_executor.as_langchain_tool()
tool3_langchain = plot_generator.as_langchain_tool()

langchain_tools = [tool1_langchain, tool2_langchain, tool3_langchain]


try:
    # Configuration du modÃ¨le langchain
    model_langchain = init_chat_model(
        "mistral-medium",
        api_key=config['api_key'],
    )
    
    agent_langchain_direct = create_react_agent(
        model_langchain, 
        langchain_tools, 
        prompt="You are a data analysis expert assistant"
    )
    
    print("Agent Langchain direct crÃ©Ã© avec succÃ¨s !")
    print(f"Nombre d'outils: {len(langchain_tools)}")
    
    question = "Donne-moi le PIB du Burkina Faso en 2020 en graphique"
    result = agent_langchain_direct.invoke({
        "messages": [("human", question)]
    })
    print(f"RÃ©sultat: {result}")
    
except Exception as e:
    print(f"Erreur: {e}")
```

![RÃ©sultat LangGraph](agent_2/langraph.png)

EUREKA, Ã§a marche aussi !

## Limitations et InconvÃ©nients des Frameworks

AprÃ¨s avoir explorÃ© les applications pratiques, il est important de discuter des limitations et dÃ©fis que vous pourriez rencontrer avec les frameworks d'agents React.

!!! warning "Attention Production"
    Les agents React introduisent une complexitÃ© et des coÃ»ts imprÃ©visibles qui nÃ©cessitent une vigilance particuliÃ¨re en production.

### ProblÃ¨mes Critiques

#### 1. **CoÃ»ts Exponentiels**
```python
# Router Agent : coÃ»t fixe et prÃ©visible
router_cost = "1-2 appels LLM â†’ ~$0.001/requÃªte"

# React Agent : coÃ»t variable et imprÃ©visible
react_cost = "1-10+ appels â†’ $0.005-0.50+/requÃªte"
```

!!! danger "Impact Financier"
    Un agent React peut coÃ»ter **50x Ã  500x plus cher** qu'un Router Agent selon la complexitÃ© de la tÃ¢che.

#### 2. **Debugging Complexe**
```python
# DifficultÃ© Ã  reproduire les erreurs
agent.run("Question complexe") 
# âŒ Ã‰chec Ã  l'Ã©tape 3/7 - workflow dynamique difficile Ã  tracer
```

#### 3. **Performances Variables**
```python
# MÃªme question, rÃ©sultats diffÃ©rents Ã  chaque exÃ©cution
question = "Analyse les PIB des pays en 2023"

# ExÃ©cution 1 : 3 Ã©tapes, 15 secondes âœ…
# ExÃ©cution 2 : 7 Ã©tapes, 45 secondes âš ï¸  
# ExÃ©cution 3 : Boucle infinie, timeout âŒ
```

#### 4. **DÃ©pendance aux LLM**
!!! warning "Risques LLM"
    - **Hallucinations** : Invention d'appels d'outils inexistants
    - **InterprÃ©tation erronÃ©e** : Mauvaise comprÃ©hension des rÃ©sultats
    - **Inconsistance** : Comportement variable selon la charge serveur

### SpÃ©cificitÃ©s par Framework

!!! info "Choix Framework"
    Chaque framework a ses propres compromis entre simplicitÃ©, fonctionnalitÃ©s et performance. Il y a beacuoup trop de framework.

#### **LangChain : L'Ã‰cosystÃ¨me Complexe**
```python
from langchain.agents import create_react_agent
# Nombreuses couches d'abstraction = debugging difficile
```

**ProblÃ¨mes spÃ©cifiques :**
- Abstractions opaques rendant le debugging complexe
- Overhead de performance dÃ» aux multiples couches
- Documentation fragmentÃ©e pour les cas avancÃ©s

#### **SmolAgent : La SimplicitÃ© Limitante**
```python
agent = ToolCallingAgent(tools=tools, model=model)
# Simple mais fonctionnalitÃ©s limitÃ©es
```

**Contraintes :**
- Pas de gestion d'Ã©tat persistant entre sessions
- Workflows complexes non supportÃ©s
- Ã‰cosystÃ¨me d'outils plus restreint

#### **LangGraph : La Configuration Verbeuse**
```python
workflow = StateGraph(State)
workflow.add_node("step1", node1)
workflow.add_edge("step1", "step2")
# Beaucoup de code pour des tÃ¢ches simples
```

**DÃ©fis d'adoption :**
- Courbe d'apprentissage trÃ¨s Ã©levÃ©e
- Over-engineering pour des cas d'usage simples
- Configuration extensive requise

### Recommandations de Production

!!! tip "StratÃ©gies de Mitigation"
    ImplÃ©mentez ces safeguards pour minimiser les risques en production.

#### **Monitoring & ContrÃ´le**
```python
# Exemple de wrapper sÃ©curisÃ©
class SafeReactAgent:
    def __init__(self, agent, max_steps=5, timeout=30):
        self.agent = agent
        self.max_steps = max_steps  # Limite les boucles infinies
        self.timeout = timeout      # Ã‰vite les blocages
    
    def run_with_fallback(self, query):
        try:
            return self.agent.run(query)
        except Exception:
            # Fallback vers Router Agent
            return self.router_fallback(query)
```

#### **Solutions RecommandÃ©es**
1. **Monitoring obligatoire** : Langfuse, Logfire ou LiteLLM
2. **Fallback systems** : Router Agent en cas d'Ã©chec
3. **Rate limiting** : `max_steps <= 10` par dÃ©faut
4. **Testing rigoureux** : Tests de charge et edge cases

!!! success "Bilan"
    Ces limitations ne doivent pas vous dissuader d'utiliser les agents React, mais vous aider Ã  prendre des dÃ©cisions Ã©clairÃ©es selon votre contexte. 



## Workflow Intelligent : Quand Utiliser Chaque Approche

### Matrice de DÃ©cision

| **CritÃ¨re** | **Router Agent** | **React Agent** |
|-------------|------------------|-----------------|
| **CoÃ»t** | ğŸ’° Bas (pas de rÃ©flexion LLM) | ğŸ’°ğŸ’° Moyen/Ã‰levÃ© (plus d'appels LLM) |
| **PrÃ©dictibilitÃ©** | âœ… Totale | âš ï¸ Variable |
| **FlexibilitÃ©** | âŒ LimitÃ©e | âœ… Ã‰levÃ©e |
| **Debugging** | âœ… Simple | âš ï¸ Plus complexe lorsqu'il y a des erreurs de type |
| **Performance** | âœ… Rapide | âš ï¸ DÃ©pend du LLM |
| **Maintenance** | âŒ Code Ã  modifier | âœ… Ajout de tools suffit |


## Conclusion

La transition des Router Agents vers les React Agents reprÃ©sente un saut qualitatif important dans la sophistication de nos systÃ¨mes d'agents IA.

L'Ã©cosystÃ¨me des agents IA Ã©volue rapidement, mais les principes fondamentaux restent : clartÃ© du design, robustesse de l'implÃ©mentation, et pragmatisme dans les choix d'architecture. En maÃ®trisant ces patterns, vous disposez maintenant des outils pour construire des agents Ã  la fois puissants et maintenables, adaptÃ©s aux exigences de production moderne.

Dans le prochain article de cette sÃ©rie, nous explorerons le MCP (Model Context Protocol). Si une API est dÃ©finie comme une communication machine-to-machine, alors MCP peut Ãªtre caractÃ©risÃ© comme une communication LLM-to-LLM, ou plus prÃ©cisÃ©ment agent-to-agent.


